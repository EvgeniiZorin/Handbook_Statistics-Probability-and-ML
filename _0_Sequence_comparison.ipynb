{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence comparison - NUMBERS\n",
    "\n",
    "- Cosine distance\n",
    "- Euclidean distance\n",
    "- Manhattan distance\n",
    "\n",
    "The closeness (similarity, nearness) of the two records (vectors) with features $(x_{1},x_{2},...,x_{n})$ and $(u_{1},u_{2},...,u_{n})$ can be measured in different ways:\n",
    "| Metric | Description | Formula | Limitations |\n",
    "| - | - | - | - |\n",
    "| Euclidean distance | Straight-line (crow's fly) distance between two points. Linear distance between two points in a multi-dimensional space. | $$ \\sqrt{(x_{1}-u_{1})^{2} + (x_{2}-u_{2})^{2} +...+(x_{n}-u_{n})^{2}} $$ | This metric is suitable for numerical continuous features. It can handle outliers and noise well. However, it can be affected by the curse of dimensionality, which means that as the number of features increases, the distance between any two points becomes less meaningful and more similar. If the data contains categorical or binary features, other distance metrics such as Hamming distance or Jaccard distance may be more appropriate. |\n",
    "| Manhattan distance (aka city block / taxicab distance) | Distance between two points if calculated going through each dimension (feature) at a time. | $$ \\|x_{1}-u_{1}\\| + \\|x_{2}-u_{2}\\| + ... + \\|x_{p}-u_{p}\\| $$ | The Manhattan distance can be used with numerical continuous variables; it is also suitable for data that has discrete and categorical features, as it does not penalize small differences as much as the Euclidean distance. It can also handle high-dimensional data better, as it is less sensitive to the curse of dimensionality. However, it can be influenced by the orientation and scale of the features, as it assumes that all directions are equally important and all units are comparable. |\n",
    "| Hamming distance | \"In information theory, the Hamming distance between two strings or vectors of equal length is the number of positions at which the corresponding symbols are different. In other words, it measures the minimum number of substitutions required to change one string into the other, or equivalently, the minimum number of errors that could have transformed one string into the other.\" | Formula is pretty complicated, so let's consider this example instead. If A = 101101, B = 100111, then hamming distance = 2. | It is used for categorical and binary features. |\n",
    "| Jaccard distance | The Jaccard distance is a measure of dissimilarity between two sets. It is defined as the size of the symmetric difference of the sets divided by the size of their union. Mathematically, the Jaccard distance between sets A and B is calculated as: | $$J(A, B) = 1 - \\frac{\\| A \\cap B \\|}{ \\| A \\cup B \\|}$$ | |\n",
    "| Minkoswki distance | A more general distance metric for KNN is the Minkowski distance, which is a generalization of the Euclidean and Manhattan distances. It is defined by a parameter p that controls how much emphasis is given to larger or smaller differences between coordinates. The Minkowski distance can be seen as a family of distance metrics that includes the Euclidean distance (p = 2), the Manhattan distance (p = 1), and the Chebyshev distance (p = infinity), which is the maximum of the absolute differences between coordinates. | $$d(x, y) = \\left( \\sum^{n}_{i=1} \\| x_{i} - y_{i} \\| ^{p} \\right)^{\\cfrac{1}{p}} $$ | The Minkowski distance is suitable for data that has mixed types of features, as it allows you to adjust the parameter p to balance the importance of different features and distances. However, it can be computationally expensive and difficult to interpret, as the parameter p can have different effects on different data sets and problems. |\n",
    "\n",
    "Other distances:\n",
    "- Mahalanobis\n",
    "- Pearson\n",
    "- Levenshtein\n",
    "- Cosine similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence comparison - TEXT\n",
    "\n",
    "> An excellent resource: https://yassineelkhal.medium.com/the-complete-guide-to-string-similarity-algorithms-1290ad07c6b7\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Algorithms:\n",
    "- Embeddings\n",
    "- Levenshtein distance\n",
    "- Hamming distance\n",
    "- Smith-Waterman distance\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edit-based algorithms\n",
    "\n",
    "> aka distance-based algorithms\n",
    "\n",
    "Measure the minimum number of single-character operations (insertions, deletions, or substitutions) required to transform one string into another. The more operations we'll have the greater the distance, and the less the similarity, will be.\n",
    "\n",
    "Used in:\n",
    "- Spell checking\n",
    "- Autocorrection\n",
    "- DNA sequence analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hamming\n",
    "\n",
    "- The number of characters that are different in two equal length strings. \n",
    "- If you overlay two strings of the same length, how many positions will have different characters; \n",
    "\n",
    "Disadvantages:\n",
    "- Strings have to be of matching lengths;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 'crook'\n",
    "b = 'shook'\n",
    "\n",
    "def hamming_distance(str1, str2):\n",
    "    assert len(str1) == len(str2)\n",
    "    hamming_distance = 0\n",
    "    for i, j in zip(str1, str2):\n",
    "        if i != j:\n",
    "            hamming_distance += 1\n",
    "    return hamming_distance\n",
    "\n",
    "hamming_distance(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0.75\n",
      "3\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "import textdistance as td\n",
    "\n",
    "a, b = 'book', 'look'\n",
    "print( td.hamming(a, b) )\n",
    "print( td.hamming.normalized_similarity(a, b) )\n",
    "c, d = 'below', 'bellow'\n",
    "print( td.hamming(c, d) ) # it automatically transforms 'below' into 'below_' to match the length of the second string, as hamming distance can only deal with equal-length strings\n",
    "print( td.hamming.normalized_similarity(c, d) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Levenshtein\n",
    "\n",
    "The minimum number of single-character edits (insertions, deletions, or substitutions) required to change one string into the other. \n",
    "\n",
    "Advantages:\n",
    "- Strings do not have to be the same length;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0.75\n"
     ]
    }
   ],
   "source": [
    "import textdistance as td\n",
    "\n",
    "# we can replace one letter by another to get the other word, so normalized similarity is (4-1)/4 = 75%\n",
    "a, b = 'book', 'look'\n",
    "print( td.levenshtein(a, b) )\n",
    "print( td.levenshtein.normalized_similarity(a, b) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "0.33333333333333337\n"
     ]
    }
   ],
   "source": [
    "print( td.levenshtein('act', 'cat') )\n",
    "print( td.levenshtein.normalized_similarity('act', 'cat') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "# we have one insertion operation, so the distance is 1 and the normalized similarity is (6-1)/6 = 84%\n",
    "c, d = 'below', 'bellow'\n",
    "print( td.levenshtein(c, d) )\n",
    "print( td.levenshtein.normalized_similarity(c, d) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Damerau-Levenshtein distance\n",
    "\n",
    "This algorithm is a variation of the Levenshtein distance that also includes the transposition operation (swapping two adjacent characters). The number of four operations (insertions, deletions, substitutions, or transposition) required to transform one string to another.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0.6666666666666667\n"
     ]
    }
   ],
   "source": [
    "import textdistance as td\n",
    "\n",
    "print( td.damerau_levenshtein('act', 'cat') )\n",
    "print( td.damerau_levenshtein.normalized_similarity('act', 'cat') )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Token-based algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequence-based algorithms"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
