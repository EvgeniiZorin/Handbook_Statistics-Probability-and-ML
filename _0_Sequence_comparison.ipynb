{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence comparison - VECTORS\n",
    "\n",
    "> a.k.a. distance measures\n",
    "\n",
    "These distance measures are used in algorithms such as k-NN, UMAP, HDBSCAN, etc. \n",
    "\n",
    "- Cosine distance\n",
    "- Euclidean distance\n",
    "- Manhattan distance\n",
    "- p-distance with the Minkowski formula\n",
    "\n",
    "The closeness (similarity, nearness) of the two records (vectors) with features $(x_{1},x_{2},...,x_{n})$ and $(u_{1},u_{2},...,u_{n})$ can be measured in different ways:\n",
    "| Metric | Description | Formula | Limitations |\n",
    "| - | - | - | - |\n",
    "| Euclidean distance | Straight-line (crow's fly) distance between two points. Linear distance between two points in a multi-dimensional space. | $$ \\sqrt{(x_{1}-u_{1})^{2} + (x_{2}-u_{2})^{2} +...+(x_{n}-u_{n})^{2}} $$ | This metric is suitable for numerical continuous features. It can handle outliers and noise well. However, it can be affected by the curse of dimensionality, which means that as the number of features increases, the distance between any two points becomes less meaningful and more similar. If the data contains categorical or binary features, other distance metrics such as Hamming distance or Jaccard distance may be more appropriate. |\n",
    "| Manhattan distance (aka city block / taxicab distance) | Distance between two points if calculated going through each dimension (feature) at a time. | $$ \\|x_{1}-u_{1}\\| + \\|x_{2}-u_{2}\\| + ... + \\|x_{p}-u_{p}\\| $$ | The Manhattan distance can be used with numerical continuous variables; it is also suitable for data that has discrete and categorical features, as it does not penalize small differences as much as the Euclidean distance. It can also handle high-dimensional data better, as it is less sensitive to the curse of dimensionality. However, it can be influenced by the orientation and scale of the features, as it assumes that all directions are equally important and all units are comparable. |\n",
    "| Hamming distance | \"In information theory, the Hamming distance between two strings or vectors of equal length is the number of positions at which the corresponding symbols are different. In other words, it measures the minimum number of substitutions required to change one string into the other, or equivalently, the minimum number of errors that could have transformed one string into the other.\" | Formula is pretty complicated, so let's consider this example instead. If A = 101101, B = 100111, then hamming distance = 2. | It is used for categorical and binary features. |\n",
    "| Jaccard distance | The Jaccard distance is a measure of dissimilarity between two sets. It is defined as the size of the symmetric difference of the sets divided by the size of their union. Mathematically, the Jaccard distance between sets A and B is calculated as: | $$J(A, B) = 1 - \\frac{\\| A \\cap B \\|}{ \\| A \\cup B \\|}$$ | |\n",
    "| Minkoswki distance | A more general distance metric for KNN is the Minkowski distance, which is a generalization of the Euclidean and Manhattan distances. It is defined by a parameter p that controls how much emphasis is given to larger or smaller differences between coordinates. The Minkowski distance can be seen as a family of distance metrics that includes the Euclidean distance (p = 2), the Manhattan distance (p = 1), and the Chebyshev distance (p = infinity), which is the maximum of the absolute differences between coordinates. | $$d(x, y) = \\left( \\sum^{n}_{i=1} \\| x_{i} - y_{i} \\| ^{p} \\right)^{\\cfrac{1}{p}} $$ | The Minkowski distance is suitable for data that has mixed types of features, as it allows you to adjust the parameter p to balance the importance of different features and distances. However, it can be computationally expensive and difficult to interpret, as the parameter p can have different effects on different data sets and problems. |\n",
    "\n",
    "Other distances:\n",
    "- Mahalanobis\n",
    "- Pearson\n",
    "- Levenshtein\n",
    "- Cosine similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence comparison - TEXT\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abcds\n",
    "abcde\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## String similarity\n",
    "\n",
    "> a.k.a. string metric, string similarity metric, string distance function\n",
    "\n",
    "> An excellent resource: https://yassineelkhal.medium.com/the-complete-guide-to-string-similarity-algorithms-1290ad07c6b7\n",
    "\n",
    "Algorithms:\n",
    "- Embeddings\n",
    "- Levenshtein distance\n",
    "- Hamming distance\n",
    "- Smith-Waterman distance\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edit-based algorithms\n",
    "\n",
    "> aka distance-based algorithms\n",
    "\n",
    "Measure the minimum number of single-character operations (insertions, deletions, or substitutions) required to transform one string into another. The more operations we'll have the greater the distance, and the less the similarity, will be.\n",
    "\n",
    "Used in:\n",
    "- Spell checking\n",
    "- Autocorrection\n",
    "- DNA sequence analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hamming\n",
    "\n",
    "- The number of characters that are different in two equal length strings. \n",
    "- If you overlay two strings of the same length, how many positions will have different characters; \n",
    "- <u>Allows only substitution</u>\n",
    "\n",
    "Disadvantages:\n",
    "- Strings have to be of matching lengths;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abcde\n",
    "abcee\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def hamming_distance(str1, str2):\n",
    "    assert len(str1) == len(str2)\n",
    "    hamming_distance = 0\n",
    "    for i, j in zip(str1, str2):\n",
    "        if i != j:\n",
    "            hamming_distance += 1\n",
    "    return hamming_distance\n",
    "\n",
    "a = 'crook'\n",
    "b = 'shook'\n",
    "hamming_distance(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0.75\n"
     ]
    }
   ],
   "source": [
    "import textdistance as td\n",
    "\n",
    "a = 'book'\n",
    "b = 'look'\n",
    "print( td.hamming(a, b) )\n",
    "print( td.hamming.normalized_similarity(a, b) ) # 3 / 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "c = 'below'\n",
    "d = 'bellow'\n",
    "print( td.hamming(c, d) ) # it automatically transforms 'below' into 'below_' to match the length of the second string, as hamming distance can only deal with equal-length strings\n",
    "print( td.hamming.normalized_similarity(c, d) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Levenshtein\n",
    "\n",
    "The minimum number of three single-character edits (insertions, deletions, or substitutions) required to change one string into the other. \n",
    "\n",
    "Advantages:\n",
    "- Strings do not have to be the same length;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0.75\n"
     ]
    }
   ],
   "source": [
    "import textdistance as td\n",
    "\n",
    "# we can replace one letter by another to get the other word, so normalized similarity is (4-1)/4 = 75%\n",
    "a = 'book'\n",
    "b = 'look'\n",
    "print( td.levenshtein(a, b) )\n",
    "print( td.levenshtein.normalized_similarity(a, b) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "0.33333333333333337\n"
     ]
    }
   ],
   "source": [
    "c = 'act'\n",
    "d = 'cat'\n",
    "print( td.levenshtein(c, d) )\n",
    "print( td.levenshtein.normalized_similarity(c, d) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "# we have one insertion operation, so the distance is 1 and the normalized similarity is (6-1)/6 = 84%\n",
    "a = 'below'\n",
    "b = 'bellow'\n",
    "print( td.levenshtein(a, b) )\n",
    "print( td.levenshtein.normalized_similarity(a, b) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "0.6666666666666667\n"
     ]
    }
   ],
   "source": [
    "a = 'below'\n",
    "b = 'mellow'\n",
    "print( td.levenshtein(a, b) )\n",
    "print( td.levenshtein.normalized_similarity(a, b) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Damerau-Levenshtein distance\n",
    "\n",
    "This algorithm is a variation of the Levenshtein distance that also includes the transposition operation (swapping two <u>adjacent characters</u>). The number of four operations (insertions, deletions, substitutions, or transposition) required to transform one string to another.  \n",
    "\n",
    "Usage:\n",
    "- NLP fields - spell checking and sequence analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0.75\n"
     ]
    }
   ],
   "source": [
    "import textdistance as td\n",
    "\n",
    "a = 'acts'\n",
    "b = 'cats'\n",
    "print( td.damerau_levenshtein(a, b) )\n",
    "print( td.damerau_levenshtein.normalized_similarity(a, b) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "0.6666666666666667\n"
     ]
    }
   ],
   "source": [
    "a = 'aaaaaa'\n",
    "b = '_aaa_a'\n",
    "print( td.damerau_levenshtein(a, b) )\n",
    "print( td.damerau_levenshtein.normalized_similarity(a, b) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Jaro similarity\n",
    "\n",
    "> Not a distance but a similarity score between 0 and 1.\n",
    "\n",
    "Jaro is an algorithm based on the number of matching characters and on transpositions like the Damerau-Levenstein do except we don’t have the adjacency constraint. The method uses an intuitive formula:\n",
    "\n",
    "$$\n",
    "\\text{Jaro similarity formula:}\n",
    "\\\\~\\\\\n",
    "d_{j_{s_{1}, s_{2}}} = \n",
    "    \\frac{1}{3} \n",
    "    \\left( \n",
    "        \\frac{m}{|s_{1}|} + \\frac{m}{|s_{2}|} + \\frac{m-t}{m}\n",
    "    \\right) \\text{ , where: }\n",
    "\\\\~\\\\\n",
    "\\begin{split}\n",
    "    & d_{j_{s_{1}, s_{2}}} : \\text{Jaro distance between string $s_{1}$ and $s_{2}$} \\\\\n",
    "    & m : \\text{the number of matching characters between $s_{1}$ and $s_{2}$. } \\\\\n",
    "    & t : \\text{the number of transpositions needed to do} \\\\\n",
    "    & |s_{1}| : \\text{the length of the first string $s_{1}$} \\\\\n",
    "    & |s_{2}| : \\text{the length of the second string $s_{2}$} \\\\\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "> Two characters from $s_{1}$ and $s_{2}$ respectively are considered matching only if they are the same and not farther than $\\cfrac{max(|s_{1}|, |s_{2}|)}{2} - 1$ characters apart.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9444444444444445"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "we have 5 matching characters \n",
    "and one insertion (this is not a transposition operation) \n",
    "so the Jaro similarity is 1/3*(5/6+5/5+6/6). \n",
    "\"\"\"\n",
    "a = 'bellow'\n",
    "b = 'below'\n",
    "td.jaro(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "we have 0 matching characters \n",
    "because the common characters are not in the range of max(|s1|, |s2|)/2–1. \n",
    "This is why the jaro similarity is 0. \n",
    "\"\"\"\n",
    "a = 'simple'\n",
    "b = 'plesim'\n",
    "td.jaro(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9166666666666666"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "The final example we have 4 matching characters and \n",
    "1 transposition operation between the first and second letter \n",
    "so the Jaro similarity is 1/3 * (4/4+4/4+3/4) = 0.91\n",
    "\"\"\"\n",
    "a = 'jaro'\n",
    "b = 'ajro'\n",
    "td.jaro(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Jaro-Winkler\n",
    "\n",
    "> https://en.wikipedia.org/wiki/Jaro%E2%80%93Winkler_distance\n",
    "\n",
    "The Jaro winkler is a modification of Jaro similarity. It is designed to give more weight to the common prefix of the strings. This is going to give greater score to strings that have the first l characters in common. Its formula is:\n",
    "\n",
    "$$\n",
    "\\text{Jaro-Winkler similarity:}\n",
    "\\\\~\\\\\n",
    "\\text{sim$_w$} = \\text{sim$_j$} + lp(1 - \\text{sim$_j$})\n",
    "\\\\~\\\\\n",
    "\\begin{split}\n",
    "    & \\text{sim$_j$ : Jaro similarity for strings $s_1$ and $s_2$} \\\\\n",
    "    & \\text{$l$ : length of common prefix at the start of the string up to a max of 4 characters} \\\\\n",
    "    & \\text{$p$ : constant scaling factor for how much the score is adjusted upwards for having common prefixes.} \\\\\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{Jaro-Winkler distance : }\n",
    "\\\\~\\\\\n",
    "d_{w} = 1 - \\text{sim$_w$}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7000000000000001"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "td.jaro(\"simple\", \"since\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.76"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "td.jaro_winkler(\"simple\", \"since\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Token-based algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequence-based algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequence alignment\n",
    "\n",
    "- Brute force\n",
    "- Needleman-Wunsch\n",
    "- Smith-Waterman\n",
    "- BLAST\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "GATTAGACCAT\n",
    "GATCAGACTAT\n",
    "\n",
    "GATTAGACCAT\n",
    "GATGAC\n",
    "\n",
    "GATTAGACCAT\n",
    "TAGA\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "match =+1\n",
    "gap =-1\n",
    "mismatch =0\n",
    "\n",
    "GATTAGACCAT\n",
    "___TAGA____\n",
    "\n",
    "GATTAGACCAT\n",
    "___TAG___A_\n",
    "\n",
    "\n",
    "\n",
    "GATTAGACCAT\n",
    "   TAGA    \n",
    "\"\"\"\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
