{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Big data\n",
    "\n",
    "Big data tools:\n",
    "- Apache Hadoop: powerful open-source framework, big data processing\n",
    "- Apache Spark: open-source framework for big data processing and analytics; \n",
    "- Apache Kafka: real-time data streaming and processing\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas\n",
    "\n",
    "You can use pandas dataframe's parameter `chunksize` to process a huge dataset\n",
    " in chunks. \n",
    "This way, you are using CPU to calculate over smaller chunks\n",
    "without having to store the entire thing in your RAM.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['row_id', 'timestamp', 'user_id', 'content_id', 'content_type_id',\n",
      "       'task_container_id', 'user_answer', 'answered_correctly',\n",
      "       'prior_question_elapsed_time', 'prior_question_had_explanation'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>user_id</th>\n",
       "      <th>content_id</th>\n",
       "      <th>content_type_id</th>\n",
       "      <th>task_container_id</th>\n",
       "      <th>user_answer</th>\n",
       "      <th>answered_correctly</th>\n",
       "      <th>prior_question_elapsed_time</th>\n",
       "      <th>prior_question_had_explanation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>115</td>\n",
       "      <td>5692</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>56943</td>\n",
       "      <td>115</td>\n",
       "      <td>5716</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>37000.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>118363</td>\n",
       "      <td>115</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>55000.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>131167</td>\n",
       "      <td>115</td>\n",
       "      <td>7860</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>19000.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>137965</td>\n",
       "      <td>115</td>\n",
       "      <td>7922</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11000.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>95</td>\n",
       "      <td>835457</td>\n",
       "      <td>2746</td>\n",
       "      <td>484</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>5382</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>97</td>\n",
       "      <td>39828</td>\n",
       "      <td>5382</td>\n",
       "      <td>3944</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>24000.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>98</td>\n",
       "      <td>132189</td>\n",
       "      <td>5382</td>\n",
       "      <td>217</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>35000.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>99</td>\n",
       "      <td>153727</td>\n",
       "      <td>5382</td>\n",
       "      <td>5844</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>88000.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    row_id  timestamp  user_id  content_id  content_type_id  \\\n",
       "0        0          0      115        5692                0   \n",
       "1        1      56943      115        5716                0   \n",
       "2        2     118363      115         128                0   \n",
       "3        3     131167      115        7860                0   \n",
       "4        4     137965      115        7922                0   \n",
       "..     ...        ...      ...         ...              ...   \n",
       "95      95     835457     2746         484                0   \n",
       "96      96          0     5382        5000                0   \n",
       "97      97      39828     5382        3944                0   \n",
       "98      98     132189     5382         217                0   \n",
       "99      99     153727     5382        5844                0   \n",
       "\n",
       "    task_container_id  user_answer  answered_correctly  \\\n",
       "0                   1            3                   1   \n",
       "1                   2            2                   1   \n",
       "2                   0            0                   1   \n",
       "3                   3            0                   1   \n",
       "4                   4            1                   1   \n",
       "..                ...          ...                 ...   \n",
       "95                 19            0                   1   \n",
       "96                  0            0                   1   \n",
       "97                  1            1                   0   \n",
       "98                  2            0                   1   \n",
       "99                  3            1                   0   \n",
       "\n",
       "    prior_question_elapsed_time prior_question_had_explanation  \n",
       "0                           NaN                            NaN  \n",
       "1                       37000.0                          False  \n",
       "2                       55000.0                          False  \n",
       "3                       19000.0                          False  \n",
       "4                       11000.0                          False  \n",
       "..                          ...                            ...  \n",
       "95                      20000.0                           True  \n",
       "96                          NaN                            NaN  \n",
       "97                      24000.0                          False  \n",
       "98                      35000.0                          False  \n",
       "99                      88000.0                          False  \n",
       "\n",
       "[100 rows x 10 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\"\"\"\n",
    "Load only the first 100 rows\n",
    "\"\"\"\n",
    "df_100 = pd.read_csv('../train.csv', nrows=100)\n",
    "print(df_100.columns)\n",
    "df_100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time consumed(s): 441.95269910000025\n",
      "Number of data points processed: 10,000,000\n",
      "Average of these data points: 5219.595430638324\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Calculate average of a column\n",
    "\"\"\"\n",
    "from timeit import default_timer as timer\n",
    "import numpy as np\n",
    "\n",
    "list1, counter = [], 0\n",
    "chunksize = 1000\n",
    "how_many_chunks_to_process = 10000\n",
    "\n",
    "start = timer()\n",
    "for chunk in pd.read_csv('../train.csv', chunksize=chunksize):\n",
    "    # list1.extend( chunk['content_id'].tolist() )\n",
    "    ### Instead of the line above, where we append all lines to a list\n",
    "    ### and then calculate average of everything at the end, \n",
    "    ### it is more optimal to append average of each chunk \n",
    "    ### and then at the end calculate average of averages, like in the operation below\n",
    "    list1.append( np.mean(chunk['content_id'].tolist()) )\n",
    "    ### If you want to process the entire data\n",
    "    ### simply remove the counter and break below\n",
    "    counter += 1\n",
    "    # if counter == how_many_chunks_to_process:\n",
    "    #     stop = timer()\n",
    "    #     break\n",
    "\n",
    "stop = timer()\n",
    "\n",
    "print(f\"Time consumed(s): {stop-start:,}\")\n",
    "print(f\"Number of data points processed: {chunksize*counter:,}\")\n",
    "avrg = sum(list1) / len(list1)\n",
    "print(f\"Average of these data points: {avrg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\evgen\\AppData\\Local\\Temp\\ipykernel_21268\\3454544260.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  details['count'] = 1\n",
      "C:\\Users\\evgen\\AppData\\Local\\Temp\\ipykernel_21268\\3454544260.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  details['count'] = 1\n",
      "C:\\Users\\evgen\\AppData\\Local\\Temp\\ipykernel_21268\\3454544260.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  details['count'] = 1\n",
      "C:\\Users\\evgen\\AppData\\Local\\Temp\\ipykernel_21268\\3454544260.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  details['count'] = 1\n",
      "C:\\Users\\evgen\\AppData\\Local\\Temp\\ipykernel_21268\\3454544260.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  details['count'] = 1\n",
      "C:\\Users\\evgen\\AppData\\Local\\Temp\\ipykernel_21268\\3454544260.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  details['count'] = 1\n",
      "C:\\Users\\evgen\\AppData\\Local\\Temp\\ipykernel_21268\\3454544260.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  details['count'] = 1\n",
      "C:\\Users\\evgen\\AppData\\Local\\Temp\\ipykernel_21268\\3454544260.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  details['count'] = 1\n",
      "C:\\Users\\evgen\\AppData\\Local\\Temp\\ipykernel_21268\\3454544260.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  details['count'] = 1\n",
      "C:\\Users\\evgen\\AppData\\Local\\Temp\\ipykernel_21268\\3454544260.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  details['count'] = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>content_type_id</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>115</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>124</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2746</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2746</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5382</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5382</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8623</td>\n",
       "      <td>0</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8623</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8701</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>12741</td>\n",
       "      <td>0</td>\n",
       "      <td>265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>12741</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13134</td>\n",
       "      <td>0</td>\n",
       "      <td>371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13134</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13134</td>\n",
       "      <td>0</td>\n",
       "      <td>872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>13134</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    user_id  content_type_id  count\n",
       "0       115                0     46\n",
       "1       124                0     30\n",
       "2      2746                0     19\n",
       "3      2746                1      1\n",
       "4      5382                0    125\n",
       "5      5382                1      3\n",
       "6      8623                0    109\n",
       "7      8623                1      3\n",
       "8      8701                0     17\n",
       "9     12741                0    265\n",
       "10    12741                1      6\n",
       "11    13134                0    371\n",
       "12    13134                1      5\n",
       "13    13134                0    872\n",
       "14    13134                1      2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>content_type_id</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>115</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>124</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2746</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2746</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5382</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5382</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8623</td>\n",
       "      <td>0</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8623</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8701</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>12741</td>\n",
       "      <td>0</td>\n",
       "      <td>265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>12741</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13134</td>\n",
       "      <td>0</td>\n",
       "      <td>1243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13134</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>24418</td>\n",
       "      <td>0</td>\n",
       "      <td>6283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>24418</td>\n",
       "      <td>1</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>24600</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>32421</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>40828</td>\n",
       "      <td>0</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>40828</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>44331</td>\n",
       "      <td>0</td>\n",
       "      <td>291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>44331</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>45001</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>46886</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>46886</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>50132</td>\n",
       "      <td>0</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>51285</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>53842</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>81002</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>81429</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>91216</td>\n",
       "      <td>0</td>\n",
       "      <td>916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>91216</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    user_id  content_type_id  count\n",
       "0       115                0     46\n",
       "1       124                0     30\n",
       "2      2746                0     19\n",
       "3      2746                1      1\n",
       "4      5382                0    125\n",
       "5      5382                1      3\n",
       "6      8623                0    109\n",
       "7      8623                1      3\n",
       "8      8701                0     17\n",
       "9     12741                0    265\n",
       "10    12741                1      6\n",
       "11    13134                0   1243\n",
       "12    13134                1      7\n",
       "13    24418                0   6283\n",
       "14    24418                1    181\n",
       "15    24600                0     50\n",
       "16    32421                0     30\n",
       "17    40828                0     92\n",
       "18    40828                1      1\n",
       "19    44331                0    291\n",
       "20    44331                1      3\n",
       "21    45001                0     30\n",
       "22    46886                0     44\n",
       "23    46886                1      1\n",
       "24    50132                0     74\n",
       "25    51285                0     22\n",
       "26    53842                0     30\n",
       "27    81002                0     17\n",
       "28    81429                0     30\n",
       "29    91216                0    916\n",
       "30    91216                1     31"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Grouby and count by groups and subgroups\n",
    "\"\"\"\n",
    "df = pd.read_csv('../train.csv', chunksize=1000)\n",
    "counter = 0\n",
    "\n",
    "output = pd.DataFrame()\n",
    "for chunk in df:\n",
    "    categories = ['user_id', 'content_type_id']\n",
    "    details = chunk[categories]\n",
    "    details['count'] = 1\n",
    "    summary = details.groupby(categories).sum().reset_index()\n",
    "    # output = output.append(summary, ignore_index=True)\n",
    "    output = pd.concat([output, summary], ignore_index=True)\n",
    "    counter += 1\n",
    "    if counter == 10:\n",
    "        break\n",
    "\n",
    "display(output.head(15))\n",
    "\n",
    "final_output = output.groupby(categories).sum().reset_index()\n",
    "# final_output.to_csv('aggregated-information-from-big-data.csv', index=False)\n",
    "final_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hadoop\n",
    "\n",
    "- Has distributed processing of data which uses multiple computers to make calculations\n",
    "- Two important components of Hadoop:\n",
    "  - HDFS / Hadoop Distributed File System: used for storing data across multiple computers\n",
    "  - MapReduce: helps process data in parallel\n",
    "- Limitations:\n",
    "  - Relies on storing data on disk, which makes things slower\n",
    "  - Processes data in batches only\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PySpark\n",
    "\n",
    "**Introduction to Spark**\n",
    "\n",
    "- Powerful tool for processing and analysing big data\n",
    "- RDD: Resilient Distributed Dataset\n",
    "- 100x faster than Hadoop\n",
    "- Manages and coordinates the execution of tasks on data across a cluster of computers\n",
    "- Components:\n",
    "  - Spark Core\n",
    "  - Spark SQL\n",
    "  - Spark Streaming\n",
    "  - Spark ML\n",
    "- Spark uses lazy evaluation\n",
    "\n",
    "https://www.youtube.com/watch?v=cZS5xYYIPzk&list=WL&index=5\n",
    "\n",
    "**PySpark Installation**\n",
    "\n",
    "`pip install pyspark`\n",
    "\n",
    "from within your conda environment: `conda install openjdk`\n",
    "\n",
    "**Some important notes**\n",
    "\n",
    "PySpark DataFrame is not the same as Pandas DataFrame\n",
    "\n",
    "directed acyclic graph (DAG) is the way Spark runs computations\n",
    "- lazy execution\n",
    "- optimization by planning ahead\n",
    "- builds a graph of transformations and applies them lasily, only when it must\n",
    "\n",
    "PySpark to Pandas\n",
    "`pd_df = df.toPandas()`\n",
    "\n",
    "Pandas to PySpark\n",
    "`spark_df = spark.createDataFrame(pd_df)`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://host.docker.internal:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1cb43a06eb0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import FloatType\n",
    "\n",
    "### Initiate a Spark session\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "### or\n",
    "# spark = SparkSession.builder.appName('test').getOrCreate()\n",
    "\n",
    "### Check session details\n",
    "spark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+--------------------+------+----+-----+-----+----------------+-------+--------+\n",
      "|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Embarked|\n",
      "+--------+------+--------------------+------+----+-----+-----+----------------+-------+--------+\n",
      "|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25|       S|\n",
      "|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|       C|\n",
      "|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925|       S|\n",
      "|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1|       S|\n",
      "|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05|       S|\n",
      "|       0|     3|    Moran, Mr. James|  male|28.0|    0|    0|          330877| 8.4583|       Q|\n",
      "|       0|     1|McCarthy, Mr. Tim...|  male|54.0|    0|    0|           17463|51.8625|       S|\n",
      "|       0|     3|Palsson, Master. ...|  male| 2.0|    3|    1|          349909| 21.075|       S|\n",
      "|       1|     3|Johnson, Mrs. Osc...|female|27.0|    0|    2|          347742|11.1333|       S|\n",
      "|       1|     2|Nasser, Mrs. Nich...|female|14.0|    1|    0|          237736|30.0708|       C|\n",
      "|       1|     3|Sandstrom, Miss. ...|female| 4.0|    1|    1|         PP 9549|   16.7|       S|\n",
      "|       1|     1|Bonnell, Miss. El...|female|58.0|    0|    0|          113783|  26.55|       S|\n",
      "|       0|     3|Saundercock, Mr. ...|  male|20.0|    0|    0|       A/5. 2151|   8.05|       S|\n",
      "|       0|     3|Andersson, Mr. An...|  male|39.0|    1|    5|          347082| 31.275|       S|\n",
      "|       0|     3|Vestrom, Miss. Hu...|female|14.0|    0|    0|          350406| 7.8542|       S|\n",
      "|       1|     2|Hewlett, Mrs. (Ma...|female|55.0|    0|    0|          248706|   16.0|       S|\n",
      "|       0|     3|Rice, Master. Eugene|  male| 2.0|    4|    1|          382652| 29.125|       Q|\n",
      "|       1|     2|Williams, Mr. Cha...|  male|28.0|    0|    0|          244373|   13.0|       S|\n",
      "|       0|     3|Vander Planke, Mr...|female|31.0|    1|    0|          345763|   18.0|       S|\n",
      "|       1|     3|Masselmani, Mrs. ...|female|28.0|    0|    0|            2649|  7.225|       C|\n",
      "+--------+------+--------------------+------+----+-----+-----+----------------+-------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Survived', 'string'),\n",
       " ('Pclass', 'string'),\n",
       " ('Name', 'string'),\n",
       " ('Sex', 'string'),\n",
       " ('Age', 'string'),\n",
       " ('SibSp', 'string'),\n",
       " ('Parch', 'string'),\n",
       " ('Ticket', 'string'),\n",
       " ('Fare', 'string'),\n",
       " ('Embarked', 'string')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Read data\n",
    "\n",
    "### Option 1: reads all columns as string\n",
    "df = spark.read.csv('clean_titanic_data.csv', header=True)\n",
    "df = spark.read.option('header', 'true').csv('clean_titanic_data.csv')\n",
    "### You can also specify data schema\n",
    "# schema = 'Age INTEGER, Sex STRING, ChestPainType STRING'\n",
    "# df = spark.read.csv('name.csv', schema=schema, header=True)\n",
    "### Get PYSpark to infer data schema by itself\n",
    "# df = spark.read.csv('name.csv', inferSchema=True, header=True)\n",
    "### Replace null values with another value \n",
    "# df = spark.read.csv('name.csv', nullValue='NA')\n",
    "\n",
    "### Saving data\n",
    "### Cannot overwrite\n",
    "# df.write.format('csv').save('path/to/save/output.csv')\n",
    "### Overwrite if exists\n",
    "# df.write.format('csv').mode('overwrite').save('path/to/save/output.csv')\n",
    "\n",
    "df.show()\n",
    "df.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------+\n",
      "|summary|               Age|   Sex|\n",
      "+-------+------------------+------+\n",
      "|  count|               891|   891|\n",
      "|   mean| 29.36158249158249|  NULL|\n",
      "| stddev|13.019696550973201|  NULL|\n",
      "|    min|              0.42|female|\n",
      "|    max|               9.0|  male|\n",
      "+-------+------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Summary statistics\n",
    "df.select(['Age', 'Sex']).describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Survived: string (nullable = true)\n",
      " |-- Pclass: string (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: string (nullable = true)\n",
      " |-- SibSp: string (nullable = true)\n",
      " |-- Parch: string (nullable = true)\n",
      " |-- Ticket: string (nullable = true)\n",
      " |-- Fare: string (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      "\n",
      "+--------+------+--------------------+------+----+-----+-----+----------------+-------+--------+\n",
      "|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Embarked|\n",
      "+--------+------+--------------------+------+----+-----+-----+----------------+-------+--------+\n",
      "|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25|       S|\n",
      "|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|       C|\n",
      "|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925|       S|\n",
      "+--------+------+--------------------+------+----+-----+-----+----------------+-------+--------+\n",
      "only showing top 3 rows\n",
      "\n",
      "+--------------------+\n",
      "|                Name|\n",
      "+--------------------+\n",
      "|Braund, Mr. Owen ...|\n",
      "|Cumings, Mrs. Joh...|\n",
      "|Heikkinen, Miss. ...|\n",
      "+--------------------+\n",
      "only showing top 3 rows\n",
      "\n",
      "+--------------------+------+\n",
      "|                Name|   Sex|\n",
      "+--------------------+------+\n",
      "|Braund, Mr. Owen ...|  male|\n",
      "|Cumings, Mrs. Joh...|female|\n",
      "|Heikkinen, Miss. ...|female|\n",
      "+--------------------+------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Show column data types\n",
    "df.dtypes\n",
    "df.printSchema()\n",
    "### Change column data type\n",
    "# df = df.withColumn('Age', df.Age.cast(FloatType()))\n",
    "\n",
    "### Remove column\n",
    "# df.drop('Age')\n",
    "### Rename column\n",
    "# df.withColumnRenamed('Age', 'age')\n",
    "### Rename multiple columns\n",
    "# name_pairs = [('Age', 'age'), ('Sex', 'sex')]\n",
    "# for old_name, new_name in name_pairs:\n",
    "#     df = df.withColumnRenamed(old_name, new_name)\n",
    "\n",
    "\n",
    "### Show the number of rows\n",
    "df.count()\n",
    "\n",
    "### Show first few rows of a table\n",
    "df.show(3)\n",
    "### Only for selected columns\n",
    "df.select('Name').show(3)\n",
    "df.select(['Name', 'Sex']).show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+--------------------+------+----+-----+-----+----------------+-------+--------+\n",
      "|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Embarked|\n",
      "+--------+------+--------------------+------+----+-----+-----+----------------+-------+--------+\n",
      "|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25|       S|\n",
      "|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|       C|\n",
      "|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925|       S|\n",
      "|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1|       S|\n",
      "|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05|       S|\n",
      "|       0|     3|    Moran, Mr. James|  male|28.0|    0|    0|          330877| 8.4583|       Q|\n",
      "|       0|     1|McCarthy, Mr. Tim...|  male|54.0|    0|    0|           17463|51.8625|       S|\n",
      "|       0|     3|Palsson, Master. ...|  male| 2.0|    3|    1|          349909| 21.075|       S|\n",
      "|       1|     3|Johnson, Mrs. Osc...|female|27.0|    0|    2|          347742|11.1333|       S|\n",
      "|       1|     2|Nasser, Mrs. Nich...|female|14.0|    1|    0|          237736|30.0708|       C|\n",
      "+--------+------+--------------------+------+----+-----+-----+----------------+-------+--------+\n",
      "\n",
      "+--------+------+--------------------+------+----+-----+-----+----------------+-------+--------+\n",
      "|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Embarked|\n",
      "+--------+------+--------------------+------+----+-----+-----+----------------+-------+--------+\n",
      "|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25|       S|\n",
      "|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|       C|\n",
      "|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925|       S|\n",
      "|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1|       S|\n",
      "|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05|       S|\n",
      "|       0|     3|    Moran, Mr. James|  male|28.0|    0|    0|          330877| 8.4583|       Q|\n",
      "|       0|     1|McCarthy, Mr. Tim...|  male|54.0|    0|    0|           17463|51.8625|       S|\n",
      "|       0|     3|Palsson, Master. ...|  male| 2.0|    3|    1|          349909| 21.075|       S|\n",
      "|       1|     3|Johnson, Mrs. Osc...|female|27.0|    0|    2|          347742|11.1333|       S|\n",
      "|       1|     2|Nasser, Mrs. Nich...|female|14.0|    1|    0|          237736|30.0708|       C|\n",
      "+--------+------+--------------------+------+----+-----+-----+----------------+-------+--------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.25</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.925</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.05</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Moran, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330877</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>McCarthy, Mr. Timothy J</td>\n",
       "      <td>male</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17463</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Palsson, Master. Gosta Leonard</td>\n",
       "      <td>male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>349909</td>\n",
       "      <td>21.075</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)</td>\n",
       "      <td>female</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>347742</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Nasser, Mrs. Nicholas (Adele Achem)</td>\n",
       "      <td>female</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>237736</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Survived Pclass                                               Name     Sex  \\\n",
       "0        0      3                            Braund, Mr. Owen Harris    male   \n",
       "1        1      1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female   \n",
       "2        1      3                             Heikkinen, Miss. Laina  female   \n",
       "3        1      1       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female   \n",
       "4        0      3                           Allen, Mr. William Henry    male   \n",
       "5        0      3                                   Moran, Mr. James    male   \n",
       "6        0      1                            McCarthy, Mr. Timothy J    male   \n",
       "7        0      3                     Palsson, Master. Gosta Leonard    male   \n",
       "8        1      3  Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)  female   \n",
       "9        1      2                Nasser, Mrs. Nicholas (Adele Achem)  female   \n",
       "\n",
       "    Age SibSp Parch            Ticket     Fare Embarked  \n",
       "0  22.0     1     0         A/5 21171     7.25        S  \n",
       "1  38.0     1     0          PC 17599  71.2833        C  \n",
       "2  26.0     0     0  STON/O2. 3101282    7.925        S  \n",
       "3  35.0     1     0            113803     53.1        S  \n",
       "4  35.0     0     0            373450     8.05        S  \n",
       "5  28.0     0     0            330877   8.4583        Q  \n",
       "6  54.0     0     0             17463  51.8625        S  \n",
       "7   2.0     3     1            349909   21.075        S  \n",
       "8  27.0     0     2            347742  11.1333        S  \n",
       "9  14.0     1     0            237736  30.0708        C  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### SQL\n",
    "\n",
    "df.createOrReplaceTempView('df') # add the table to the database catalog\n",
    "\n",
    "df_top10 = spark.sql('SELECT * FROM df LIMIT 10')\n",
    "df_top10.show()\n",
    "\n",
    "spark.sql(\"SELECT * FROM df LIMIT 10\").show()\n",
    "\n",
    "# Can later convert the result of the query to a dataframe\n",
    "tips10_df = df_top10.toPandas()\n",
    "tips10_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|Pclass|count|\n",
      "+------+-----+\n",
      "|     3|  491|\n",
      "|     1|  216|\n",
      "|     2|  184|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### count\n",
    "\n",
    "df.groupby('Pclass').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+----+\n",
      "|Pclass|female|male|\n",
      "+------+------+----+\n",
      "|     3|   144| 347|\n",
      "|     1|    94| 122|\n",
      "|     2|    76| 108|\n",
      "+------+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Pivoting\n",
    "df.groupby('Pclass').pivot('Sex').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+--------------------+------+----+-----+-----+----------------+-------+--------+\n",
      "|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Embarked|\n",
      "+--------+------+--------------------+------+----+-----+-----+----------------+-------+--------+\n",
      "|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925|       S|\n",
      "|       1|     3|Johnson, Mrs. Osc...|female|27.0|    0|    2|          347742|11.1333|       S|\n",
      "|       1|     3|Sandstrom, Miss. ...|female| 4.0|    1|    1|         PP 9549|   16.7|       S|\n",
      "|       0|     3|Vestrom, Miss. Hu...|female|14.0|    0|    0|          350406| 7.8542|       S|\n",
      "|       0|     3|Vander Planke, Mr...|female|31.0|    1|    0|          345763|   18.0|       S|\n",
      "|       1|     3|Masselmani, Mrs. ...|female|28.0|    0|    0|            2649|  7.225|       C|\n",
      "|       1|     3|\"McGowan, Miss. A...|female|15.0|    0|    0|          330923| 8.0292|       Q|\n",
      "|       0|     3|Palsson, Miss. To...|female| 8.0|    3|    1|          349909| 21.075|       S|\n",
      "|       1|     3|Asplund, Mrs. Car...|female|38.0|    1|    5|          347077|31.3875|       S|\n",
      "|       1|     3|\"O'Dwyer, Miss. E...|female|28.0|    0|    0|          330959| 7.8792|       Q|\n",
      "|       1|     3|Glynn, Miss. Mary...|female|28.0|    0|    0|          335677|   7.75|       Q|\n",
      "|       0|     3|Vander Planke, Mi...|female|18.0|    2|    0|          345764|   18.0|       S|\n",
      "|       1|     3|Nicola-Yarred, Mi...|female|14.0|    1|    0|            2651|11.2417|       C|\n",
      "|       0|     3|Ahlin, Mrs. Johan...|female|40.0|    1|    0|            7546|  9.475|       S|\n",
      "|       1|     3|Devaney, Miss. Ma...|female|19.0|    0|    0|          330958| 7.8792|       Q|\n",
      "|       1|     3|O'Driscoll, Miss....|female|28.0|    0|    0|           14311|   7.75|       Q|\n",
      "|       0|     3|Arnold-Franchi, M...|female|18.0|    1|    0|          349237|   17.8|       S|\n",
      "|       1|     3|Andersson, Miss. ...|female|17.0|    4|    2|         3101281|  7.925|       S|\n",
      "|       0|     3|Goodwin, Miss. Li...|female|16.0|    5|    2|         CA 2144|   46.9|       S|\n",
      "|       1|     3|Dowdell, Miss. El...|female|30.0|    0|    0|          364516| 12.475|       S|\n",
      "+--------+------+--------------------+------+----+-----+-----+----------------+-------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Filtering\n",
    "\n",
    "### many interchangeable options\n",
    "df.filter('age > 18')\n",
    "df.where('age > 18')\n",
    "df.where(df['age'] > 18)\n",
    "### Use AND (&) or OR (|) operators\n",
    "df.where((df['age'] > 18) & (df['sex'] == 'male'))\n",
    "### Rows that do NOT meet the criteria\n",
    "df.filter(~(df['Sex'] == 'male'))\n",
    "\n",
    "df_03 = df.filter(df.Sex == 'female').filter(df.Pclass == 3)\n",
    "df_03.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Survived: string, Pclass: string, Name: string, Sex: string, Age: string, SibSp: string, Parch: string, Ticket: string, Fare: string, Embarked: string, survived_pclass: double]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Evaluating a string\n",
    "from pyspark.sql.functions import expr\n",
    "\n",
    "survived_pclass = 'Survived * Pclass + 0'\n",
    "df.withColumn('survived_pclass', expr(survived_pclass))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Survived: string (nullable = true)\n",
      " |-- Pclass: string (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: string (nullable = true)\n",
      " |-- SibSp: string (nullable = true)\n",
      " |-- Parch: string (nullable = true)\n",
      " |-- Ticket: string (nullable = true)\n",
      " |-- Fare: string (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+------------------+\n",
      "|summary|   Sex|               Age|\n",
      "+-------+------+------------------+\n",
      "|  count|   891|               891|\n",
      "|   mean|  NULL| 29.36158249158249|\n",
      "| stddev|  NULL|13.019696550973201|\n",
      "|    min|female|              0.42|\n",
      "|    max|  male|               9.0|\n",
      "+-------+------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(['Sex', 'Age']).describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop na\n",
    "### drop all rows that contain a single null value\n",
    "df = df.na.drop()\n",
    "### drop rows that has all null values\n",
    "df = df.na.drop(how='all')\n",
    "### drop rows that has the number of null values exceeding a specified threshold\n",
    "df = df.na.drop(thresh=2)\n",
    "### drop null values for specified columns only\n",
    "df = df.na.drop(how='any', subset=['age', 'sex'])\n",
    "### replace null values with a specified value\n",
    "df = df.na.fill(value='?', subset=['sex'])\n",
    "\n",
    "### Using imputer strategy\n",
    "from pyspark.ml.feature import Imputer\n",
    "imptr = Imputer(inputCols=['age', 'RestingBP'],\n",
    "                outputCols=['age', 'RestingBP']).setStrategy('mean')\n",
    "df = imptr.fit(df).transform(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+--------------------+------+----+-----+-----+----------------+-------+--------+\n",
      "|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Embarked|\n",
      "+--------+------+--------------------+------+----+-----+-----+----------------+-------+--------+\n",
      "|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25|       S|\n",
      "|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|       C|\n",
      "|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925|       S|\n",
      "|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1|       S|\n",
      "|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05|       S|\n",
      "|       0|     3|    Moran, Mr. James|  male|28.0|    0|    0|          330877| 8.4583|       Q|\n",
      "|       0|     1|McCarthy, Mr. Tim...|  male|54.0|    0|    0|           17463|51.8625|       S|\n",
      "|       0|     3|Palsson, Master. ...|  male| 2.0|    3|    1|          349909| 21.075|       S|\n",
      "|       1|     3|Johnson, Mrs. Osc...|female|27.0|    0|    2|          347742|11.1333|       S|\n",
      "|       1|     2|Nasser, Mrs. Nich...|female|14.0|    1|    0|          237736|30.0708|       C|\n",
      "|       1|     3|Sandstrom, Miss. ...|female| 4.0|    1|    1|         PP 9549|   16.7|       S|\n",
      "|       1|     1|Bonnell, Miss. El...|female|58.0|    0|    0|          113783|  26.55|       S|\n",
      "|       0|     3|Saundercock, Mr. ...|  male|20.0|    0|    0|       A/5. 2151|   8.05|       S|\n",
      "|       0|     3|Andersson, Mr. An...|  male|39.0|    1|    5|          347082| 31.275|       S|\n",
      "|       0|     3|Vestrom, Miss. Hu...|female|14.0|    0|    0|          350406| 7.8542|       S|\n",
      "|       1|     2|Hewlett, Mrs. (Ma...|female|55.0|    0|    0|          248706|   16.0|       S|\n",
      "|       0|     3|Rice, Master. Eugene|  male| 2.0|    4|    1|          382652| 29.125|       Q|\n",
      "|       1|     2|Williams, Mr. Cha...|  male|28.0|    0|    0|          244373|   13.0|       S|\n",
      "|       0|     3|Vander Planke, Mr...|female|31.0|    1|    0|          345763|   18.0|       S|\n",
      "|       1|     3|Masselmani, Mrs. ...|female|28.0|    0|    0|            2649|  7.225|       C|\n",
      "+--------+------+--------------------+------+----+-----+-----+----------------+-------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------------+\n",
      "|   Sex|          avg(Age)|\n",
      "+------+------------------+\n",
      "|female|27.929936305732483|\n",
      "|  male| 30.14067590987868|\n",
      "+------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df.groupby('Sex').agg({'Age': 'mean'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------------+\n",
      "|   Sex|          avg(Age)|\n",
      "+------+------------------+\n",
      "|  male| 30.14067590987868|\n",
      "|female|27.929936305732483|\n",
      "+------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import desc\n",
    "\n",
    "df.groupby('Sex').agg({'Age': 'mean'}).orderBy(desc('avg(Age)')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+-----------------+\n",
      "|   Sex|min(Age)|      avg(Pclass)|\n",
      "+------+--------+-----------------+\n",
      "|female|    0.75|2.159235668789809|\n",
      "|  male|    0.42|2.389948006932409|\n",
      "+------+--------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "df.groupby('Sex').agg(F.min(df['Age']), F.avg(df['Pclass'])).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+--------------------+------+----+-----+-----+----------------+-------+--------+\n",
      "|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Embarked|\n",
      "+--------+------+--------------------+------+----+-----+-----+----------------+-------+--------+\n",
      "|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25|       S|\n",
      "|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|       C|\n",
      "|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925|       S|\n",
      "+--------+------+--------------------+------+----+-----+-----+----------------+-------+--------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "IllegalArgumentException",
     "evalue": "Output column Fvec already exists.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIllegalArgumentException\u001b[0m                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mwithColumn(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSurvived\u001b[39m\u001b[38;5;124m'\u001b[39m, df\u001b[38;5;241m.\u001b[39mSurvived\u001b[38;5;241m.\u001b[39mcast(FloatType()))\n\u001b[0;32m     11\u001b[0m v_asmblr \u001b[38;5;241m=\u001b[39m VectorAssembler(inputCols\u001b[38;5;241m=\u001b[39mX_column_names, outputCol\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFvec\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 12\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mv_asmblr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\evgen\\.conda\\envs\\data-science\\lib\\site-packages\\pyspark\\ml\\base.py:262\u001b[0m, in \u001b[0;36mTransformer.transform\u001b[1;34m(self, dataset, params)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy(params)\u001b[38;5;241m.\u001b[39m_transform(dataset)\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    263\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    264\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParams must be a param map but got \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mtype\u001b[39m(params))\n",
      "File \u001b[1;32mc:\\Users\\evgen\\.conda\\envs\\data-science\\lib\\site-packages\\pyspark\\ml\\wrapper.py:398\u001b[0m, in \u001b[0;36mJavaTransformer._transform\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    395\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_java_obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    397\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transfer_params_to_java()\n\u001b[1;32m--> 398\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_java_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[43m)\u001b[49m, dataset\u001b[38;5;241m.\u001b[39msparkSession)\n",
      "File \u001b[1;32mc:\\Users\\evgen\\.conda\\envs\\data-science\\lib\\site-packages\\py4j\\java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[1;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[0;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\evgen\\.conda\\envs\\data-science\\lib\\site-packages\\pyspark\\errors\\exceptions\\captured.py:185\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    181\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[0;32m    184\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[1;32m--> 185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    187\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[1;31mIllegalArgumentException\u001b[0m: Output column Fvec already exists."
     ]
    }
   ],
   "source": [
    "### Machine Learning with spark\n",
    "# pyspark won't accept a table of feature column, but \n",
    "# needs a vector of feature columns\n",
    "\n",
    "X_column_names = ['Age', 'SibSp']\n",
    "\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "df = df.withColumn('Age', df.Age.cast(FloatType()))\n",
    "df = df.withColumn('SibSp', df.SibSp.cast(FloatType()))\n",
    "df = df.withColumn('Survived', df.Survived.cast(FloatType()))\n",
    "v_asmblr = VectorAssembler(inputCols=X_column_names, outputCol='Fvec')\n",
    "df = v_asmblr.transform(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[48], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mregression\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LinearRegression\n\u001b[0;32m      3\u001b[0m model \u001b[38;5;241m=\u001b[39m LinearRegression(featuresCol\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFvec\u001b[39m\u001b[38;5;124m'\u001b[39m, labelCol\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSurvived\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(\u001b[43mtrainset\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'trainset' is not defined"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "model = LinearRegression(featuresCol='Fvec', labelCol='Survived')\n",
    "model = model.fit(trainset)\n",
    "print(model.coefficients, model.intercept)\n",
    "\n",
    "model.evaluate(testset).predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-science",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
